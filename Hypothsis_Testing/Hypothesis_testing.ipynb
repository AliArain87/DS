{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapiro Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "\n",
    "#set seed (e.g. make this example reproducible)\n",
    "seed(0)\n",
    "\n",
    "#generate dataset of 100 random values that follow a standard normal distribution\n",
    "data = randn(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9926937818527222, pvalue=0.8689165711402893)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "#perform Shapiro-Wilk test\n",
    "shapiro(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9979248046875, pvalue=0.8062111139297485)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import useful library\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "from numpy.random import randn\n",
    "\n",
    "# Create data\n",
    "gfg_data = randn(500)\n",
    "\n",
    "# conduct the  Shapiro-Wilk Test\n",
    "shapiro(gfg_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to normalize data methods\n",
    "###### We are going to discuss two different ways to normalize data in python.\n",
    "###### The first one is by using the method ‘normalize()‘ under sklearn.\n",
    "###### Using MinMaxScaler() to Normalize Data in Python\n",
    "###### Sklearn provides another option when it comes to normalizing data: MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11785113 0.1767767  0.29462783 0.35355339 0.41247896 0.23570226\n",
      "  0.47140452 0.41247896 0.35355339]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "x_array = np.array([2, 3, 5, 6, 7, 4, 8, 7, 6])\n",
    "normalized_arr = preprocessing.normalize([x_array])\n",
    "print(normalized_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e626341f7d273a073ca6760d51f453142864e91a54b48c38f50eacc9d94e2c4c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
