{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><i> Report</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><i> EDA On Video With OpenCV<i><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyone who wants to follow it so he/she require to install some libraries first for example : cv2,numpy,re\n",
    "# If you are a windows user so use \"pip install library-name\"\n",
    "# If you are a Mac user so use \"pip3 install library-name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. First of all, We will need a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For video creation, The code is given below:\n",
    "\n",
    "# To record video from cam on pc\n",
    "from re import L\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "cap.set(cv.CAP_PROP_FOURCC, cv.VideoWriter_fourcc(\n",
    "    'M', 'J', 'P', 'G'))  # depends on fourcc available camera\n",
    "#cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "#cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv.CAP_PROP_FPS, 30)\n",
    "print(cap.get(cv.CAP_PROP_FPS))\n",
    "# resolution\n",
    "\n",
    "def hd_resolution():\n",
    "    cap.set(3, 1280)  # width\n",
    "    cap.set(4, 720)  # height\n",
    "\n",
    "def sd_resolution():\n",
    "    cap.set(3, 640)  # width\n",
    "    cap.set(4, 480)  # height\n",
    "\n",
    "\n",
    "def fhd_resolution():\n",
    "    cap.set(3, 1920)  # width\n",
    "    cap.set(4, 1080)  # height\n",
    "\n",
    "fhd_resolution()\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv.imshow(\"Camera\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. To perform eda on a video we will need to break it into frames to get images from it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split your video into frame\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('Resources/VideoCP17.avi')\n",
    "\n",
    "frameNr = 0\n",
    "\n",
    "while(True):\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        cv.imwrite(f\"Resources/Task/frame_{frameNr}.jpg\", frame)\n",
    "    else:\n",
    "        break\n",
    "    frameNr = frameNr+1\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Now we can perform different function on the frames such as:\n",
    "#####   (i). Manipulate images or remove noise from images\n",
    "#####  (ii). Detect face or any object from images\n",
    "##### (iii). Change perception of image \n",
    "#####  (iv). Joining two images\n",
    "#####   (v). and many more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ANONYM~1\\AppData\\Local\\Temp/ipykernel_8000/2061741779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresized_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m450\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# gray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# (i)\n",
    "# basic functions or manipulation in one cv\n",
    "\n",
    "import cv2 as cv\n",
    "img = cv.imread(\"Resources/GateM.jpg\")\n",
    "\n",
    "# resize\n",
    "resized_img = cv.resize(img, (450, 250))\n",
    "\n",
    "# gray\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# blurred image\n",
    "blur_img = cv.GaussianBlur(img, (7, 7), 0)  # 7,7 odd matrix\n",
    "\n",
    "# Edge detection\n",
    "edge_img = cv.Canny(img, 48, 48)\n",
    "\n",
    "# Thickness of lines\n",
    "\n",
    "dilated_img = cv.dilate(edge_img, (7, 7), iterations=1)\n",
    "\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Gray Image\", gray_img)\n",
    "cv.imshow(\"Blur Image\", blur_img)\n",
    "cv.imshow(\"Edge Image\", edge_img)\n",
    "cv.imshow(\"Dilated Image\", dilated_img)\n",
    "cv.imshow(\"Resized image\", resized_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii)\n",
    "# Face detection in images\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(\n",
    "    'Resources/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv.imread(\"Resources/2.JPG\")\n",
    "img = cv.resize(img, (591, 886))\n",
    "\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.1, 4)\n",
    "print(img.shape)\n",
    "\n",
    "# Draw a rectangle\n",
    "for (x, y, w, h) in faces:\n",
    "    cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "cv.imshow(\"Image\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii)\n",
    "# # how to change the perspective of an image\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('Resources/2.JPG')\n",
    "\n",
    "# width and height\n",
    "print(img.shape)\n",
    "\n",
    "#Defining points\n",
    "point1 = np.float32([[233, 196], [82, 471], [522, 169], [715, 482]])\n",
    "\n",
    "width = 800\n",
    "height = 900\n",
    "# or width,height = 800,900\n",
    "point2 = np.float32([[0, 0], [800, 0], [0, height], [width, height]])\n",
    "\n",
    "matrix = cv.getPerspectiveTransform(point1, point2)\n",
    "\n",
    "out_img = cv.warpPerspective(img, matrix, (width, height))\n",
    "#out_img = cv.resize\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Transformed\", out_img)\n",
    "cv.imwrite('Resources/2.0.JPG')\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv)\n",
    "# Joining two images\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"Resources/GateM.jpg\")\n",
    "\n",
    "# Stacking same image\n",
    "\n",
    "#1- Horizontal stack\n",
    "\n",
    "hor_img = np.hstack((img, img))\n",
    "\n",
    "#2- Vertical stack\n",
    "\n",
    "ver_img = np.vstack((img, img))\n",
    "\n",
    "\n",
    "#cv.imshow(\"Horizontal\",hor_img)\n",
    "cv.imshow(\"Vertucal\", ver_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e626341f7d273a073ca6760d51f453142864e91a54b48c38f50eacc9d94e2c4c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
